# VisionMate â€“ Smart Navigation for the Blind

An AI-powered obstacle detection and navigation assistance app for visually impaired users, built with Flutter, YOLOv8 and on-device Reinforcement Learning.

![Flutter](https://img.shields.io/badge/Flutter-3.0+-blue.svg)
![Platform](https://img.shields.io/badge/Platform-Android-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## Features

### ğŸ¯ Object Detection
- Real-time obstacle detection using YOLOv8n ONNX model
- 80 object class recognition (COCO dataset)
- Distance estimation in human terms ("two steps ahead")
- Stairs detection using edge heuristics

### ğŸ”Š Audio Guidance
- Calm, natural TTS announcements with emotional support
- Confidence-aware speech ("I think I see...")
- Spatial audio hints (left/right/ahead)
- Customizable speech rate and volume
- Path clear notifications

### ğŸ§  Reinforcement Learning
- On-device Q-Learning agent
- Learns optimal announcement timing from feedback
- Object preference learning (which obstacles matter to you)
- Epsilon-greedy exploration â†’ exploitation over time
- Persistent Q-table across sessions

### ğŸ—£ï¸ Voice Commands
- Natural language understanding
- "What's ahead", "Find the door", "Help me"
- "Read this" â€“ OCR text reading
- "What note is this" â€“ Currency identification (â‚¹)
- "Thanks" / "Too much" â€“ Feedback for learning

### ğŸ“³ Haptic Feedback
- Proximity-based vibration intensity
- Different patterns for danger levels (critical/high/medium/low)
- Emergency vibration patterns

### ğŸ†˜ Safety Features
- Emergency SOS with GPS location
- Fall detection with auto-SOS (30s countdown)
- "I'm okay" voice cancellation
- Sends SMS to emergency contact
- Detection history logging

### â™¿ Accessibility
- Large touch buttons (80-100px)
- Screen reader support (Semantics)
- High contrast mode
- Hands-free activation (shake, volume button, double-tap)
- Beginner / Advanced personalization modes

## Installation

### Prerequisites
- Flutter SDK 3.0+
- Android device with camera
- YOLOv8n ONNX model file

### Steps

1. **Clone the repository**
   ```bash
   git clone https://github.com/HARSH07YADAV/Blind-Assist-Nav.git
   cd Blind-Assist-Nav/flutter_app
   ```

2. **Get dependencies**
   ```bash
   flutter pub get
   ```

3. **Run the app**
   ```bash
   flutter run --release
   ```

## Project Structure

```
flutter_app/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ main.dart
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ risk_calculator.dart
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ detection.dart
â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â”œâ”€â”€ home_screen.dart
â”‚   â”‚   â”œâ”€â”€ settings_screen.dart
â”‚   â”‚   â””â”€â”€ history_screen.dart
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ camera_service.dart
â”‚   â”‚   â”œâ”€â”€ onnx_service.dart
â”‚   â”‚   â”œâ”€â”€ tts_service.dart
â”‚   â”‚   â”œâ”€â”€ haptic_service.dart
â”‚   â”‚   â”œâ”€â”€ settings_service.dart
â”‚   â”‚   â”œâ”€â”€ history_service.dart
â”‚   â”‚   â”œâ”€â”€ emergency_service.dart
â”‚   â”‚   â”œâ”€â”€ voice_command_service.dart
â”‚   â”‚   â”œâ”€â”€ tracking_service.dart
â”‚   â”‚   â”œâ”€â”€ navigation_guidance_service.dart
â”‚   â”‚   â”œâ”€â”€ accessibility_activation_service.dart
â”‚   â”‚   â”œâ”€â”€ ocr_service.dart
â”‚   â”‚   â”œâ”€â”€ context_service.dart
â”‚   â”‚   â”œâ”€â”€ currency_service.dart
â”‚   â”‚   â”œâ”€â”€ learning_service.dart       # Q-Learning agent
â”‚   â”‚   â””â”€â”€ feedback_service.dart       # Preference learning
â”‚   â””â”€â”€ widgets/
â”‚       â””â”€â”€ detection_overlay.dart
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ yolov8n.onnx
â”‚       â””â”€â”€ labels.txt
â””â”€â”€ android/
    â””â”€â”€ app/src/main/AndroidManifest.xml
```

## How It Works

1. **Camera Feed** â†’ Captures frames at 4 FPS
2. **YOLOv8 Inference** â†’ Detects objects using ONNX Runtime
3. **Risk Analysis** â†’ Calculates danger based on distance and type
4. **Q-Learning Decision** â†’ Should I announce? Calm or urgent?
5. **TTS + Haptic** â†’ Announces and vibrates based on urgency
6. **User Feedback** â†’ "Thanks" or "Too much" updates Q-table

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- [YOLOv8](https://github.com/ultralytics/ultralytics) - Object detection model
- [Flutter](https://flutter.dev) - Cross-platform framework
- [ONNX Runtime](https://onnxruntime.ai) - ML inference engine
